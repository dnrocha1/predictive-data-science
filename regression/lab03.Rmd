---
title: "Predição de Deputados Eleitos"
author: "Daniyel Rocha"
date: "03 de dezembro de 2018"
output: 
  html_document:
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r include=FALSE}
library(tidyverse)
library(dplyr)
library(caret)
library(caTools)
library(unbalanced)
library(DMwR)
```

# Introdução

```{r}
train <- read.csv("data/lab03/train.csv")
test <- read.csv("data/lab03/test.csv")
```

# 1 Há desbalanceamento das classes (isto é, uma classe tem muito mais instâncias que outra)? Em que proporção? Quais efeitos colaterais o desbalanceamento de classes pode causar no classificador? Como você poderia tratar isso? (10 pt.)
```{r}
summary(train$situacao)
balanced_data <- DMwR::SMOTE(train$situacao ~., data = train, perc.over = 600, perc.under = 100)
summary(balanced_data$situacao)
#https://rpubs.com/abhaypadda/smote-for-imbalanced-data
```

# 2 Treine: um modelo de regressão logística, uma árvore de decisão e um modelo de adaboost. Tune esses modelos usando validação cruzada e controle overfitting se necessário, considerando as particularidades de cada modelo.  (20 pts.)

```{r}
#configuracao da validacao cruzada
ctrl <- trainControl(
  method = "cv",
  number = 5,
  verboseIter = TRUE
  )

log_reg <- caret::train(
  situacao ~.,
  data = train %>% select(-cargo),
  method = "glm",
  family = "binomial",
  trControl = ctrl
)
```

