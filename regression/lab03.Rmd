---
title: "Predição de Deputados Eleitos"
author: "Daniyel Rocha"
date: "03 de dezembro de 2018"
output: 
  html_document:
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r include=FALSE}
library(tidyverse)
library(dplyr)
library(caret)
library(rpart)
library(rpart.plot)
# library(DMwR)
# library(caTools)
# library(unbalanced)
```

# Introdução

```{r}
train <- read.csv("data/lab03/train.csv")
test <- read.csv("data/lab03/test.csv")

input <- train %>% 
  select(-cargo, -nome, -ocupacao, -ano, -sequencial_candidato, -uf, -sexo, -estado_civil, -grau, -partido)

```

# 1 Há desbalanceamento das classes (isto é, uma classe tem muito mais instâncias que outra)? Em que proporção? Quais efeitos colaterais o desbalanceamento de classes pode causar no classificador? Como você poderia tratar isso? (10 pt.)
```{r}
summary(train$situacao)
# balanced_data <- DMwR::SMOTE(train$situacao ~., data = train, perc.over = 600, perc.under = 100)
# summary(balanced_data$situacao)
#https://rpubs.com/abhaypadda/smote-for-imbalanced-data

round((summary(input$situacao)/sum(summary(input$situacao))), 2)

```
Podemos observar desbalanceamento das classes, considerando `situacao`, que é a variável alvo. Há muito mais ocorrências de `nao_eleito`, cerca de 87%, contra uma proporção bem menor em relação a candidatos que foram eleitos, representando cerca de 13% do conjunto total. Essa situação pode fazer com que os modelos produzidos classifiquem de forma incorreta os dados reais. Isso acontece porque geralmente modelos de classificação são mais sensíveis a classes desbalanceadas, fazendo com que o modelo final tenha uma tendência de predizer a classe com um maior número de ocorrências.  
De forma a não afetar tanto o modelo final, uma abordagem possível é balancear as classes. Dessa maneira é possível aproximar o número de instâncias da classe, permitindo que o modelo seja treinado e testado sem ser muito afetado pelo desbalanceamento. Para que isso seja feito, é possível aumentar a frequência da classe minoritária (over-sampling) ou então diminuir o número de ocorrências da classe maioritária (under-sampling), cada uma apresentando vantagens e desvantagens.

# 2 Treine: um modelo de KNN, regressão logística, uma árvore de decisão e um modelo de adaboost. Tune esses modelos usando validação cruzada e controle overfitting se necessário, considerando as particularidades de cada modelo.  (20 pts.)

```{r}
#configuracao da validacao cruzada
ctrl <- trainControl(
  sampling = "smote",
  method = "cv",
  number = 5,
  # search = "random",
  verboseIter = TRUE
  )
```

```{r}
#knn

knn.range <- expand.grid(k = seq(1, 500, length = 60))

model.knn <- caret::train(
  situacao ~.,
  data = input,
  method = "knn",
  trControl = ctrl,
  tuneGrid = knn.range,
  preProcess = c('scale', 'center', 'nzv')
)

model.knn
plot(model.knn)
```


```{r}
#logistic
model.logistic <- caret::train(
  situacao ~.,
  data = input,
  method = "glm",
  family = "binomial",
  trControl = ctrl,
  preProcess = c('scale', 'center', 'nzv')
)

model.logistic
model.logistic %>% confusionMatrix()

```


```{r}
#decision tree
model.dt <- caret::train(
  situacao ~.,
  data = input,
  method = "rpart",
  tuneLength = 10,
  # trControl = trainControl(sampling = "smote", method = "repeatedcv", number = 5, repeats = 5, verboseIter = TRUE),
  preProcess = c('scale', 'center', 'nzv')
)

	
model.dt
rpart.plot::prp(model.dt$finalModel, box.palette="RdBu", shadow.col="gray", nn=TRUE, extra = 1, type = 1, digits = -3)

```

```{r}
#ada boost
model.ada <- caret::train(
  situacao ~.,
  data = input,
  method = "adaboost",
  preProcess = c('scale', 'center', 'nzv'),
  verbose = TRUE
)

model.ada
plot(model.ada)

```


# 3 Reporte precision, recall e f-measure no treino e validação. Há uma grande diferença de desempenho no treino/validação? Como você avalia os resultados? Justifique sua resposta. (10 pt.)

```{r}
confusionMatrix(data = model.logistic)

input %>% colnames()

```

```{r}
model.xgboost <- caret::train(
  situacao ~.,
  data = input,
  method = "xgbTree",
  trControl = trainControl(method = "cv", number = 3),
  preProcess = c('scale', 'center', 'nzv'),
  verbose = TRUE
)

model.xgboost
plot(model.xgboost)
```


```{r}
model.svm <- caret::train(
  situacao ~.,
  data = input,
  method = "svmLinear",
  trControl = trainControl(method = "repeatedcv", number = 5, repeats = 3),
  preProcess = c('scale', 'center', 'nzv'),
  tuneLength = 10,
  verbose = TRUE
)

model.svm
```

```{r}
model.gb <- caret::train(
  situacao ~.,
  data = input,
  method = "gbm",
  trControl = trainControl(method = 'cv', number = 5),
  preProcess = c('scale', 'center', 'nzv'),
  verbose = TRUE
)

model.gb
```



```{r}
pred <- predict(model.gb, test)
ans <- data.frame(Id = test$sequencial_candidato, Predicted = pred)
ans$Id <- as.character(ans$Id)
write_csv(ans,"data/lab03/kaggle.csv")
```

